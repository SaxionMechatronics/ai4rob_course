## Question 1
```mcq
---
type: single
question: What are the five components of an MDP?
---
- [ ] States, Actions, Policy, Rewards, Discount  
- [x] States, Actions, Transitions, Rewards, Discount  
- [ ] States, Actions, Observations, Rewards, Discount  
- [ ] States, Actions, Value function, Rewards, Discount  
```

---

## Question 2
```mcq
---
type: single
question: What does the Markov property state?
---
- [ ] The next state depends on the entire history of states and actions  
- [x] The next state depends only on the current state and action, not on history  
- [ ] The next state is always deterministic  
- [ ] The next state depends only on the current action  
```

---

## Question 3
```mcq
---
type: single
question: What is the key difference between the state-value function V and the action-value function Q?
---
- [ ] V is for deterministic policies, Q is for stochastic policies  
- [x] V is the expected return from a state following a policy, while Q is the expected return from a state after taking a specific action then following the policy  
- [ ] V is for continuous states, Q is for discrete states  
- [ ] There is no difference; they are the same function  
```

---

## Question 4
```mcq
---
type: single
question: Why is a discount factor less than 1 necessary for infinite-horizon problems?
---
- [ ] It makes the agent prefer immediate rewards over future rewards  
- [ ] It allows the agent to forget past experiences  
- [x] It ensures the infinite sum of discounted rewards converges mathematically  
- [ ] It prevents the agent from exploring too much  
```

---

## Question 5
```mcq
---
type: single
question: What is the main difference between a state and an observation in robotics?
---
- [ ] States are discrete, observations are continuous  
- [x] States contain complete information about the environment, while observations are partial and noisy measurements that the agent actually perceives  
- [ ] States are what the agent controls, observations are what the environment controls  
- [ ] There is no difference; they are the same thing  
```

